<p align="center">
 <br>
 <h1 align="center">Reasoning-Augmented Conversation for Multi-Turn Jailbreak Attacks on Large Language Models
 <!-- <br>   -->
 </h1>
</p>


Official implementation of **RACE**. 

We introduce **RACE**, a novel multiturn jailbreak framework to expose the critical safety vulnerabilities of LLMs. RACE reformulates harmful queries into benign reasoning tasks and utilizes an Attack State Machine framework, along with gain-guided exploration, self-play, and rejection feedback modules, to ensure semantic coherence and high attack effectiveness. Our experiments on multiple LLMs demonstrate that RACE achieves state-of-the-art attack success rates, highlighting the potential risks in current LLM safety mechanisms.

# <img src="resources/main.png" width="90%">


## Experiment Results

# <img src="resources/result1.png" width="90%">

# <img src="resources/result2.png" width="90%">

## Start

**We have already updated part of the code, and all of our code will be released soon!**


